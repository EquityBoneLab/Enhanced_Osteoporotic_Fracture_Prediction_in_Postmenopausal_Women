{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve,f1_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, BatchNormalization, Dropout\n",
    "from keras.optimizers import Adam, SGD, RMSprop, Adadelta, Adagrad, Adamax, Nadam\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from math import floor\n",
    "from sklearn.metrics import make_scorer, accuracy_score\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from keras.layers import LeakyReLU\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "LeakyReLU = LeakyReLU(alpha=0.1)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "import pickle\n",
    "from imblearn.over_sampling import SMOTE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make scorer accuracy\n",
    "score_acc = make_scorer(accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset with FRAX CRFs and GRS\n",
    "with open('ready_whi_sp23', 'rb') as file_handler:\n",
    "    data = pickle.load(file_handler)\n",
    "    X1, Y1 = data.get('X', []).values, data.get('Y', []).values\n",
    "x_train1, x_test1, y_train1, y_test1 = train_test_split(X1, Y1, test_size=0.2,random_state=98)\n",
    "sm = SMOTE(random_state=2)\n",
    "x_train_s1, y_train_s1 = sm.fit_resample(x_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset with FRAX CRFs (no grs)\n",
    "with open('ready_whi_sp23', 'rb') as file_handler:\n",
    "    data = pickle.load(file_handler)\n",
    "    X2, Y2 = data.get('X_nogrs', []).values, data.get('Y', []).values\n",
    "x_train2, x_test2, y_train2, y_test2 = train_test_split(X2, Y2, test_size=0.2,random_state=98)\n",
    "sm = SMOTE(random_state=2)\n",
    "x_train_s2, y_train_s2 = sm.fit_resample(x_train2, y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bayesian optimization for Model 4 (FRAX CRFs + GRS)\n",
    "def nn_cl_bo(neurons,learning_rate, dropout,\n",
    "             batch_size, epochs):\n",
    "    optimizerD= {'Adam':Adam(lr=learning_rate)}\n",
    "    neurons = round(neurons)\n",
    "    batch_size = round(batch_size)\n",
    "    epochs = round(epochs)\n",
    "    dropout = dropout\n",
    "    def nn_cl_fun():\n",
    "        opt = Adam(lr = learning_rate)\n",
    "        nn = Sequential()\n",
    "        nn.add(Dense(neurons, input_dim=31, activation='relu'))\n",
    "        nn.add(Dropout(dropout))\n",
    "        nn.add(Dense(neurons, activation='relu'))\n",
    "        nn.add(Dropout(dropout))\n",
    "        nn.add(Dense(1, activation='sigmoid'))\n",
    "        nn.compile(loss='binary_crossentropy', optimizer='adam', \n",
    "                   metrics=['accuracy'])\n",
    "        return nn\n",
    "    es = EarlyStopping(monitor='accuracy', mode='max', verbose=0, patience=20)\n",
    "    nn = KerasClassifier(build_fn=nn_cl_fun, epochs=epochs, batch_size=batch_size,\n",
    "                         verbose=0)\n",
    "    kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=123)\n",
    "    score = cross_val_score(nn, x_train_s1, y_train_s1, \n",
    "                            scoring=score_acc, cv=10, \n",
    "                            fit_params={'callbacks':[es]}).mean()\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120/120 [==============================] - 2s 12ms/step\n",
      "120/120 [==============================] - 2s 12ms/step\n",
      "120/120 [==============================] - 1s 11ms/step\n",
      "120/120 [==============================] - 2s 13ms/step\n",
      "120/120 [==============================] - 2s 12ms/step\n",
      "120/120 [==============================] - 2s 11ms/step\n",
      "120/120 [==============================] - 2s 13ms/step\n",
      "120/120 [==============================] - 2s 12ms/step\n",
      "120/120 [==============================] - 2s 12ms/step\n",
      "120/120 [==============================] - 1s 5ms/step\n",
      "120/120 [==============================] - 1s 4ms/step\n",
      "120/120 [==============================] - 1s 4ms/step\n",
      "120/120 [==============================] - 1s 4ms/step\n",
      "120/120 [==============================] - 1s 5ms/step\n",
      "120/120 [==============================] - 1s 4ms/step\n",
      "120/120 [==============================] - 1s 4ms/step\n",
      "120/120 [==============================] - 1s 5ms/step\n",
      "120/120 [==============================] - 1s 5ms/step\n",
      "120/120 [==============================] - 1s 4ms/step\n",
      "120/120 [==============================] - 1s 4ms/step\n",
      "120/120 [==============================] - 1s 5ms/step\n",
      "120/120 [==============================] - 1s 4ms/step\n",
      "120/120 [==============================] - 1s 4ms/step\n",
      "120/120 [==============================] - 1s 4ms/step\n",
      "120/120 [==============================] - 1s 4ms/step\n",
      "120/120 [==============================] - 1s 5ms/step\n",
      "120/120 [==============================] - 1s 4ms/step\n",
      "120/120 [==============================] - 1s 5ms/step\n",
      "120/120 [==============================] - 1s 4ms/step\n",
      "120/120 [==============================] - 1s 4ms/step\n",
      "120/120 [==============================] - 1s 5ms/step\n",
      "120/120 [==============================] - 1s 4ms/step\n",
      "120/120 [==============================] - 1s 4ms/step\n",
      "120/120 [==============================] - 1s 4ms/step\n",
      "120/120 [==============================] - 1s 4ms/step\n",
      "120/120 [==============================] - 1s 5ms/step\n",
      "120/120 [==============================] - 1s 5ms/step\n",
      "120/120 [==============================] - 1s 5ms/step\n",
      "120/120 [==============================] - 1s 5ms/step\n",
      "120/120 [==============================] - 1s 4ms/step\n",
      "120/120 [==============================] - 1s 5ms/step\n",
      "120/120 [==============================] - 1s 5ms/step\n",
      "120/120 [==============================] - 1s 4ms/step\n",
      "120/120 [==============================] - 1s 5ms/step\n",
      "120/120 [==============================] - 1s 5ms/step\n",
      "120/120 [==============================] - 1s 4ms/step\n",
      "120/120 [==============================] - 1s 4ms/step\n",
      "120/120 [==============================] - 1s 4ms/step\n",
      "120/120 [==============================] - 1s 5ms/step\n",
      "120/120 [==============================] - 1s 4ms/step\n",
      "120/120 [==============================] - 1s 5ms/step\n",
      "120/120 [==============================] - 1s 4ms/step\n",
      "120/120 [==============================] - 1s 4ms/step\n",
      "120/120 [==============================] - 1s 4ms/step\n",
      "120/120 [==============================] - 1s 5ms/step\n",
      "120/120 [==============================] - 1s 4ms/step\n",
      "120/120 [==============================] - 1s 5ms/step\n",
      "120/120 [==============================] - 1s 5ms/step\n",
      "120/120 [==============================] - 1s 4ms/step\n",
      "120/120 [==============================] - 1s 4ms/step\n",
      "120/120 [==============================] - 1s 5ms/step\n",
      "120/120 [==============================] - 1s 5ms/step\n",
      "120/120 [==============================] - 1s 4ms/step\n",
      "120/120 [==============================] - 1s 5ms/step\n",
      "120/120 [==============================] - 1s 5ms/step\n",
      "120/120 [==============================] - 1s 5ms/step\n",
      "120/120 [==============================] - 1s 5ms/step\n",
      "120/120 [==============================] - 1s 5ms/step\n",
      "120/120 [==============================] - 1s 4ms/step\n",
      "120/120 [==============================] - 1s 5ms/step\n",
      "Final result for ANN (GRS) with Bayesian optimization: {'target': 0.8497106003708893, 'params': {'batch_size': 614.3488210891596, 'dropout': 0.08405376347880598, 'epochs': 42.554580478819304, 'learning_rate': 0.6341016716921827, 'neurons': 2316.678707100004}}\n"
     ]
    }
   ],
   "source": [
    "# Set paramaters\n",
    "params_nn ={\n",
    "    'neurons': (10, 10000),\n",
    "    'learning_rate':(0.01, 1),\n",
    "    'dropout':(0.01, 1),\n",
    "    'batch_size':(200, 1000),\n",
    "    'epochs':(20, 100)\n",
    "}\n",
    "\n",
    "nn_bo = BayesianOptimization(nn_cl_bo, params_nn, verbose=0,random_state=123)\n",
    "nn_bo.maximize(init_points=2, n_iter=5)\n",
    "print(\"Final result for ANN (GRS) with Bayesian optimization:\", nn_bo.max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bayesian optimization for Model 2 (FRAX CRFs + GRS)\n",
    "def nn_cl_bo(neurons,learning_rate, dropout,\n",
    "             batch_size, epochs):\n",
    "    optimizerD= {'Adam':Adam(lr=learning_rate)}\n",
    "    neurons = round(neurons)\n",
    "    batch_size = round(batch_size)\n",
    "    epochs = round(epochs)\n",
    "    dropout = dropout\n",
    "    def nn_cl_fun():\n",
    "        opt = Adam(lr = learning_rate)\n",
    "        nn = Sequential()\n",
    "        nn.add(Dense(neurons, input_dim=30, activation='relu'))\n",
    "        nn.add(Dropout(dropout))\n",
    "        nn.add(Dense(neurons, activation='relu'))\n",
    "        nn.add(Dropout(dropout))\n",
    "        nn.add(Dense(1, activation='sigmoid'))\n",
    "        nn.compile(loss='binary_crossentropy', optimizer='adam', \n",
    "                   metrics=['accuracy'])\n",
    "        return nn\n",
    "    es = EarlyStopping(monitor='accuracy', mode='max', verbose=0, patience=20)\n",
    "    nn = KerasClassifier(build_fn=nn_cl_fun, epochs=epochs, batch_size=batch_size,\n",
    "                         verbose=0)\n",
    "    kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=123)\n",
    "    score = cross_val_score(nn, x_train_s2, y_train_s2, \n",
    "                            scoring=score_acc, cv=10, \n",
    "                            fit_params={'callbacks':[es]}).mean() \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400/400 [==============================] - 16s 39ms/step\n",
      "400/400 [==============================] - 16s 39ms/step\n",
      "400/400 [==============================] - 16s 39ms/step\n",
      "400/400 [==============================] - 16s 39ms/step\n",
      "400/400 [==============================] - 15s 38ms/step\n",
      "400/400 [==============================] - 16s 39ms/step\n",
      "400/400 [==============================] - 15s 38ms/step\n",
      "400/400 [==============================] - 15s 37ms/step\n",
      "400/400 [==============================] - 14s 36ms/step\n",
      "400/400 [==============================] - 14s 36ms/step\n",
      "400/400 [==============================] - 15s 37ms/step\n",
      "400/400 [==============================] - 15s 37ms/step\n",
      "400/400 [==============================] - 15s 37ms/step\n",
      "400/400 [==============================] - 16s 39ms/step\n",
      "400/400 [==============================] - 15s 36ms/step\n",
      "400/400 [==============================] - 15s 36ms/step\n",
      "400/400 [==============================] - 14s 36ms/step\n",
      "400/400 [==============================] - 15s 38ms/step\n",
      "400/400 [==============================] - 15s 36ms/step\n",
      "400/400 [==============================] - 14s 36ms/step\n",
      "400/400 [==============================] - 16s 39ms/step\n",
      "Final result for ANN (no GRS) with Bayesian optimization: {'target': 0.7016578484997078, 'params': {'batch_size': 726.5190148665778, 'dropout': 0.010074801781291724, 'epochs': 60.29878750573636, 'learning_rate': 0.010630405728982002, 'neurons': 7277.230898601044}}\n"
     ]
    }
   ],
   "source": [
    "# Set paramaters\n",
    "params_nn ={\n",
    "    'neurons': (10, 10000),\n",
    "    'learning_rate':(0.01, 1),\n",
    "    'dropout':(0.01, 1),\n",
    "    'batch_size':(200, 1000),\n",
    "    'epochs':(20, 100)\n",
    "}\n",
    "nn_bo = BayesianOptimization(nn_cl_bo, params_nn, verbose=0, random_state=123)\n",
    "nn_bo.maximize(init_points=2, n_iter=5)\n",
    "print(\"Final result for ANN (no GRS) with Bayesian optimization:\", nn_bo.max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 600, 'dropout': 0.1, 'epochs': 60, 'learning_rate': 1, 'neurons': 10000}\n"
     ]
    }
   ],
   "source": [
    "# grid search for Model 3 (FRAX CRFs + GRS)\n",
    "params_nn ={\n",
    "    'neurons': [10,1000,10000],\n",
    "    'learning_rate':[0.01,0.1,1],\n",
    "    'dropout':[0.01,0.05,0.1],\n",
    "    'batch_size':[200,600,1000],\n",
    "    'epochs':[20,60,100]\n",
    "}\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "def create_model(learning_rate=0.01,dropout=0.0,neurons=1): \n",
    "    opt = Adam(lr = learning_rate)\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, input_dim=31, kernel_initializer='normal', \n",
    "                    activation='relu'))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', \n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "model = KerasClassifier(build_fn=create_model, \n",
    "                        epochs=100, \n",
    "                        batch_size=10, verbose=0)\n",
    "\n",
    "grid=GridSearchCV(estimator=model, param_grid=params_nn,verbose=0,n_jobs=-1,\n",
    "                  cv=10).fit(x_train_s1, y_train_s1) \n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 600, 'dropout': 0.01, 'epochs': 60, 'learning_rate': 0.1, 'neurons': 10000}\n"
     ]
    }
   ],
   "source": [
    "# grid search for Model 1 (FRAX CRFs)\n",
    "params_nn ={\n",
    "    'neurons': [10,1000,10000],\n",
    "    'learning_rate':[0.01,0.1,1],\n",
    "    'dropout':[0.01,0.05,0.1],\n",
    "    'batch_size':[200,600,1000],\n",
    "    'epochs':[20,60,100]\n",
    "}\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "def create_model(learning_rate=0.01,dropout=0.0,neurons=1): \n",
    "    opt = Adam(lr = learning_rate)\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neurons, input_dim=30, kernel_initializer='normal', \n",
    "                    activation='relu'))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', \n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "model = KerasClassifier(build_fn=create_model, \n",
    "                        epochs=100, \n",
    "                        batch_size=10, verbose=0)\n",
    "\n",
    "grid=GridSearchCV(estimator=model, param_grid=params_nn, verbose=0,n_jobs=-1,\n",
    "                  cv=10).fit(x_train_s2, y_train_s2) \n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
